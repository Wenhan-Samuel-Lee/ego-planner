{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, concatenate, Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from math import floor\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "# Clear logs from previous runs\n",
    "# %rm -rf ../logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_INPUTS = 15\n",
    "NUM_OUTPUTS = 11\n",
    "\n",
    "# Load the dataset input and output\n",
    "inputNums = np.loadtxt('../dataset/0_input.csv', delimiter=',') # (num training points, 13)\n",
    "y = np.loadtxt('../dataset/0_output.csv', delimiter=',') # (num training points, 11)\n",
    "X = np.zeros((len(inputNums), 480, 640, 1)) # (num training points, 480, 640)\n",
    "\n",
    "# For each of the training examples there should be exactly 1 image\n",
    "for i in range(0, len(inputNums)):\n",
    "    image = Image.open('../dataset/img_' + str(i) + '.jpg') \n",
    "    imageArr = np.asarray(image).reshape(480, 640, 1) # Converts the image into a 2D 480*640 array\n",
    "    X[i] = imageArr / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 5120)\n",
      "(None, 15)\n",
      "(None, 5135)\n",
      "Epoch 1/5\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 6.4982 - mae: 1.2935WARNING:tensorflow:From /home/wenhan/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "19/19 [==============================] - 7s 394ms/step - loss: 4.3427 - mae: 1.1983 - val_loss: 5.7431 - val_mae: 1.4426\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 7s 372ms/step - loss: 1.1032 - mae: 0.7337 - val_loss: 5.1639 - val_mae: 1.3969\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 9s 450ms/step - loss: 0.5843 - mae: 0.5323 - val_loss: 3.5931 - val_mae: 1.1986\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 9s 498ms/step - loss: 0.3894 - mae: 0.4376 - val_loss: 2.8618 - val_mae: 1.0984\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 10s 535ms/step - loss: 0.2720 - mae: 0.3703 - val_loss: 2.6355 - val_mae: 1.0795\n"
     ]
    }
   ],
   "source": [
    "numerical_inputs = Input(shape=(NUM_INPUTS,))\n",
    "image_inputs = Input(shape=(480, 640, 1))\n",
    "\n",
    "# Process the image data first\n",
    "x_image = Conv2D(32, (7, 7), strides=(4, 4), padding='same', activation='relu')(image_inputs)\n",
    "x_image = Conv2D(64, (5, 5), strides=(4, 4), padding=\"same\", activation=\"relu\")(x_image)\n",
    "x_image = Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\")(x_image)\n",
    "x_image = Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\")(x_image)\n",
    "x_image = Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\")(x_image)\n",
    "x_image = Model(image_inputs, x_image)\n",
    "x_image = Flatten()(x_image.output)\n",
    "\n",
    "print(x_image.shape)\n",
    "print(numerical_inputs.shape)\n",
    "\n",
    "# Combine the latent space representation with the numerical input\n",
    "combined = concatenate([x_image, numerical_inputs])\n",
    "print(combined.shape)\n",
    "x_combined = Dense(300, activation='relu')(combined)\n",
    "x_combined = Dense(60, activation='relu')(x_combined)\n",
    "outputs = Dense(11, activation='linear')(x_combined)\n",
    "\n",
    "model = Model([image_inputs, numerical_inputs], outputs)\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "log_dir = \"../logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = model.fit([X, inputNums], y, epochs=100, batch_size=32, validation_split=0.2, callbacks=[tensorboard_callback])\n",
    "\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/assets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-794ed3dac8eabc92\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-794ed3dac8eabc92\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('../models')\n",
    "\n",
    "# Open Tensorboard (actually, run this on the command line on your Terminal)\n",
    "# %tensorboard --logdir ../logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "loaded_model = model_load('../models')\n",
    "loaded_model.fit([X, inputNums], y, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
